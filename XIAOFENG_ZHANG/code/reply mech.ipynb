{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e58c1418-441d-4a2e-8583-106d9b38abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ab8ab1d-9fe7-4ab5-aa6c-c9daea2e4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_paths = [\n",
    "    \"../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "    \"../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "    \"../data/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "    \"../data/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"../data/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
    "    \"../data/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "    \"../data/Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"../data/Wednesday-workingHours.pcap_ISCX.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "75ce589c-8f42-49ba-b930-a98caa739b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {path}: {e}\")\n",
    "\n",
    "# Combine all data into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ea60fec6-537d-4651-b610-42f889be6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns with all NaN values and drop rows with any NaN values\n",
    "cleaned_df = combined_df.dropna(axis=1, how='all')  # Drop columns with all NaN\n",
    "cleaned_df = cleaned_df.dropna()  # Drop rows with any NaN values\n",
    "\n",
    "# Remove leading and trailing whitespaces from column names\n",
    "cleaned_df.columns = cleaned_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f4256fa-3a10-4872-bdf3-4b6a5fef0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "features = cleaned_df.drop(columns=['Label'])\n",
    "labels = cleaned_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd905dc6-6342-4d2c-9e74-053f142b08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN and then drop rows containing NaN values\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features.dropna(inplace=True)\n",
    "\n",
    "# Update labels to match the cleaned features\n",
    "labels = labels[features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a0b504e0-7577-49fd-9372-a6c967574fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "24ddf01d-e0ec-49b3-817b-d09d353c1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature columns to have zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c1cfb0e-fb8e-4f7d-aad9-fb91b8b60aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets (60% train, 20% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(scaled_features, encoded_labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b766d89-396e-4fc1-9eec-fc9437f4021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1696725, 78)\n",
      "Validation set size: (565575, 78)\n",
      "Test set size: (565576, 78)\n"
     ]
    }
   ],
   "source": [
    "# Display the size of each dataset\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce10fd0-7a2e-43a0-8f38-5d2e354cdf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5861a366-403d-4929-afe8-8e0b951bf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, classification_report, confusion_matrix, log_loss, matthews_corrcoef, balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "04a7cc54-8067-474f-b899-2870b0d517b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "results_dir = \"../data/results/malicious_pattern\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f37bf3cf-9649-4b53-b020-ccb5aa2ad10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalLearningModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(IncrementalLearningModel, self).__init__()\n",
    "        # Define neural network structure with hidden layers\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, X_train, y_train, X_val, y_val, num_epochs=50, lr=1e-4, poisoning_rate=0.0):\n",
    "        # Convert numpy arrays to torch tensors\n",
    "        train_data = X_train.clone().detach().float().to(device) if isinstance(X_train, torch.Tensor) else torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        train_labels = y_train.clone().detach().long().to(device) if isinstance(y_train, torch.Tensor) else torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "        val_data = X_val.clone().detach().float().to(device) if isinstance(X_val, torch.Tensor) else torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "        val_labels = y_val.clone().detach().long().to(device) if isinstance(y_val, torch.Tensor) else torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        # Lists to store losses for visualization\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(train_data)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record training loss\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Validation step\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = self(val_data)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        # Create directory for the specific poisoning rate\n",
    "        rate_dir = os.path.join(results_dir, f'poisoning_rate_{poisoning_rate:.2f}')\n",
    "        os.makedirs(rate_dir, exist_ok=True)\n",
    "\n",
    "        # Plot the loss curves and save\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Training and Validation Loss (Poisoning Rate {poisoning_rate:.2f})')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(rate_dir, 'training_validation_loss.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, X_test, y_test, poisoning_rate):\n",
    "        # Convert numpy arrays to torch tensors\n",
    "        test_data = X_test.clone().detach().float().to(device) if isinstance(X_test, torch.Tensor) else torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        test_labels = y_test.clone().detach().long().to(device) if isinstance(y_test, torch.Tensor) else torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "        # Predict the labels for the test data\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self(test_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Calculate accuracy, precision, recall, and F1 score\n",
    "        accuracy = accuracy_score(test_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "        precision = precision_score(test_labels.cpu().numpy(), predicted.cpu().numpy(), average='weighted', zero_division=1)\n",
    "        recall = recall_score(test_labels.cpu().numpy(), predicted.cpu().numpy(), average='weighted', zero_division=1)\n",
    "        f1 = f1_score(test_labels.cpu().numpy(), predicted.cpu().numpy(), average='weighted', zero_division=1)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Generate classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(test_labels.cpu().numpy(), predicted.cpu().numpy(), zero_division=1))\n",
    "\n",
    "        # Create subdirectory for each poisoning rate\n",
    "        rate_dir = os.path.join(results_dir, f'poisoning_rate_{poisoning_rate:.2f}')\n",
    "        os.makedirs(rate_dir, exist_ok=True)\n",
    "\n",
    "        # Plot Confusion Matrix\n",
    "        cm = confusion_matrix(test_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Confusion Matrix (Poisoning Rate {poisoning_rate:.2f})')\n",
    "        plt.savefig(os.path.join(rate_dir, 'confusion_matrix.png'))\n",
    "        plt.show()\n",
    "\n",
    "        # Generate ROC Curve and AUC if binary classification\n",
    "        if len(np.unique(test_labels.cpu().numpy())) == 2:  # Only applicable for binary classification\n",
    "            fpr, tpr, _ = roc_curve(test_labels.cpu().numpy(), outputs[:, 1].cpu().numpy())\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'Receiver Operating Characteristic (ROC) Curve (Poisoning Rate {poisoning_rate:.2f})')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(os.path.join(rate_dir, 'roc_curve.png'))\n",
    "            plt.show()\n",
    "\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e7db2855-9afd-4420-89b8-3407de19cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance\n",
    "def calculate_feature_importance(X_train, y_train):\n",
    "    # Using a simple RandomForest to evaluate feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    result = permutation_importance(rf, X_train, y_train, n_repeats=10, random_state=42)\n",
    "    return result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1c86324f-3c23-428e-b65c-c0f62556ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_data(data, labels, poisoning_rate=0.1, strategy='pgd_attack', model=None, criterion=None, epsilon=0.1, alpha=0.01, iters=10):\n",
    "    \"\"\"\n",
    "    Generate poisoned data using different strategies.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array or torch.Tensor, original input data\n",
    "    - labels: np.array or torch.Tensor, original labels\n",
    "    - poisoning_rate: float, proportion of data to be poisoned\n",
    "    - strategy: str, the type of poisoning strategy ('label_flip', 'feature_perturbation', 'pgd_attack', 'logic_disruption', 'malicious_pattern', 'combined')\n",
    "    - model: (optional) the model used for generating adversarial perturbation (required for 'pgd_attack')\n",
    "    - criterion: (optional) loss function used for generating adversarial perturbation (required for 'pgd_attack')\n",
    "    - epsilon: float, perturbation strength for adversarial attacks\n",
    "    - alpha: float, step size for PGD attack\n",
    "    - iters: int, number of iterations for PGD attack\n",
    "\n",
    "    Returns:\n",
    "    - poisoned_data: torch.Tensor, data with poisoning applied\n",
    "    - poisoned_labels: torch.Tensor, labels with poisoning applied\n",
    "    \"\"\"\n",
    "    data = data.clone().detach().float().to(device) if isinstance(data, torch.Tensor) else torch.tensor(data, dtype=torch.float32).to(device)\n",
    "    labels = labels.clone().detach().long().to(device) if isinstance(labels, torch.Tensor) else torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "    num_samples = data.shape[0]\n",
    "    num_poisoned = int(poisoning_rate * num_samples)\n",
    "    poisoned_indices = torch.tensor(random.sample(range(num_samples), num_poisoned), dtype=torch.long).to(device)\n",
    "\n",
    "    if strategy == 'pgd_attack':\n",
    "        # PGD Attack\n",
    "        if model is None or criterion is None:\n",
    "            raise ValueError(\"Model and criterion are required for 'pgd_attack' strategy.\")\n",
    "        \n",
    "        poisoned_data = data.clone().detach().to(device)\n",
    "        poisoned_data.requires_grad = False\n",
    "\n",
    "        batch_size = 16\n",
    "        for i in range(iters):\n",
    "            for start_idx in range(0, num_poisoned, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, num_poisoned)\n",
    "                batch_indices = poisoned_indices[start_idx:end_idx]\n",
    "                batch_data = poisoned_data[batch_indices].clone().detach().requires_grad_(True)  # Ensure batch_data is a leaf tensor\n",
    "                batch_labels = labels[batch_indices]\n",
    "\n",
    "                # Forward pass through the model\n",
    "                outputs = model(batch_data)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                # Zero out any previous gradients\n",
    "                model.zero_grad()\n",
    "                if batch_data.grad is not None:\n",
    "                    batch_data.grad.zero_()\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Retain gradients on batch_data so we can use them\n",
    "                batch_data.retain_grad()\n",
    "\n",
    "                # Check if gradients are available\n",
    "                if batch_data.grad is not None:\n",
    "                    # Compute perturbation\n",
    "                    gradient = batch_data.grad.sign()\n",
    "                    batch_data = batch_data + alpha * gradient\n",
    "\n",
    "                    # Clamp the perturbed data\n",
    "                    batch_data = torch.clamp(batch_data, min=data[batch_indices] - epsilon, max=data[batch_indices] + epsilon)\n",
    "                    batch_data = torch.clamp(batch_data, 0, 1)  # Assuming the data is in range [0, 1]\n",
    "\n",
    "                    # Update the poisoned data (avoid in-place modification of leaf variable)\n",
    "                    poisoned_data = poisoned_data.clone().detach()\n",
    "                    poisoned_data[batch_indices] = batch_data.clone().detach()  # Use clone().detach() to avoid in-place update of tensor requiring grad\n",
    "                else:\n",
    "                    print(\"Warning: Gradient is None during PGD attack.\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return poisoned_data.detach(), labels\n",
    "\n",
    "    elif strategy == 'label_flip':\n",
    "        # Vectorized label flipping\n",
    "        poisoned_labels = labels.clone()\n",
    "        poisoned_labels[poisoned_indices] = (labels[poisoned_indices] + 1) % len(torch.unique(labels))\n",
    "        return data, poisoned_labels\n",
    "\n",
    "    elif strategy == 'feature_perturbation':\n",
    "        # Vectorized feature perturbation\n",
    "        poisoned_data = data.clone()\n",
    "        perturbation = torch.randn_like(poisoned_data[poisoned_indices]) * 1.0  # Larger perturbation scale\n",
    "        poisoned_data[poisoned_indices] += perturbation\n",
    "        return poisoned_data, labels\n",
    "\n",
    "    elif strategy == 'combined':\n",
    "        # Combined label flipping and feature perturbation\n",
    "        poisoned_data = data.clone()\n",
    "        poisoned_labels = labels.clone()\n",
    "\n",
    "        # Apply feature perturbation\n",
    "        perturbation = torch.randn_like(poisoned_data[poisoned_indices]) * 0.5\n",
    "        poisoned_data[poisoned_indices] += perturbation\n",
    "\n",
    "        # Flip labels\n",
    "        poisoned_labels[poisoned_indices] = (labels[poisoned_indices] + 1) % len(torch.unique(labels))\n",
    "\n",
    "        return poisoned_data, poisoned_labels\n",
    "\n",
    "    elif strategy == 'logic_disruption':\n",
    "        # Logic Disruption (breaking feature relationships)\n",
    "        poisoned_data = data.clone()\n",
    "        for feature_idx in [0, 1, 2]:\n",
    "            poisoned_data[:, feature_idx] = poisoned_data[:, feature_idx][torch.randperm(poisoned_data.size(0))]\n",
    "        return poisoned_data, labels\n",
    "\n",
    "    elif strategy == 'malicious_pattern':\n",
    "        # Malicious Pattern Injection\n",
    "        poisoned_data = data.clone()\n",
    "        pattern_strength = 0.5\n",
    "        pattern = torch.randn(len(poisoned_indices), data.size(1)).to(device) * pattern_strength\n",
    "        poisoned_data[poisoned_indices] += pattern\n",
    "\n",
    "        # Randomly flip some labels to further confuse the model\n",
    "        poisoned_labels = labels.clone()\n",
    "        poisoned_labels[poisoned_indices] = (labels[poisoned_indices] + 1) % len(torch.unique(labels))\n",
    "\n",
    "        return poisoned_data, poisoned_labels\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported poisoning strategy. Available strategies: 'label_flip', 'feature_perturbation', 'pgd_attack', 'logic_disruption', 'malicious_pattern', 'combined'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6389622a-1ba5-4117-85bd-fe8f95359163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle catastrophic forgetting using Replay mechanism\n",
    "def replay_mechanism(model, previous_data, new_data, previous_labels, new_labels, num_epochs=5, lr=1e-4):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    previous_data = previous_data.clone().detach().float().to(device) if isinstance(previous_data, torch.Tensor) else torch.tensor(previous_data, dtype=torch.float32).to(device)\n",
    "    previous_labels = previous_labels.clone().detach().long().to(device) if isinstance(previous_labels, torch.Tensor) else torch.tensor(previous_labels, dtype=torch.long).to(device)\n",
    "    new_data = new_data.clone().detach().float().to(device) if isinstance(new_data, torch.Tensor) else torch.tensor(new_data, dtype=torch.float32).to(device)\n",
    "    new_labels = new_labels.clone().detach().long().to(device) if isinstance(new_labels, torch.Tensor) else torch.tensor(new_labels, dtype=torch.long).to(device)\n",
    "\n",
    "    # Combine previous and new data\n",
    "    combined_data = torch.cat((previous_data, new_data), dim=0)\n",
    "    combined_labels = torch.cat((previous_labels, new_labels), dim=0)\n",
    "\n",
    "    # Retrain the model with combined dataset\n",
    "    model.train_model(combined_data, combined_labels, combined_data, combined_labels, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "128e38ef-ad87-4755-b217-5e9f6246700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_replay_impact(results):\n",
    "    poisoning_rates = [result[\"poisoning_rate\"] for result in results]\n",
    "    accuracy_before = [result[\"accuracy_before\"] for result in results]\n",
    "    accuracy_after = [result[\"accuracy_after\"] for result in results]\n",
    "    f1_before = [result[\"f1_score_before\"] for result in results]\n",
    "    f1_after = [result[\"f1_score_after\"] for result in results]\n",
    "\n",
    "    # Plot Accuracy before and after Replay\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    width = 0.3\n",
    "    x = np.arange(len(poisoning_rates))\n",
    "    plt.bar(x - width / 2, accuracy_before, width, label='Before Replay', color='b')\n",
    "    plt.bar(x + width / 2, accuracy_after, width, label='After Replay', color='g')\n",
    "    plt.xlabel('Poisoning Rate')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Before and After Replay')\n",
    "    plt.xticks(x, [f\"{rate:.2f}\" for rate in poisoning_rates])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'accuracy_comparison.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot F1 Score before and after Replay\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(x - width / 2, f1_before, width, label='Before Replay', color='r')\n",
    "    plt.bar(x + width / 2, f1_after, width, label='After Replay', color='g')\n",
    "    plt.xlabel('Poisoning Rate')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score Before and After Replay')\n",
    "    plt.xticks(x, [f\"{rate:.2f}\" for rate in poisoning_rates])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'f1_score_comparison.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7921a636-6fac-4824-accc-0a550bef080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_poisoning_experiment_with_replay(model, X_train, y_train, X_val, y_val, X_test, y_test, poisoning_rates, replay_data, replay_labels, num_epochs=50, lr=1e-4):\n",
    "    results = []\n",
    "    results_csv_path = os.path.join(results_dir, \"poisoning_experiment_results.csv\")\n",
    "    results_json_path = os.path.join(results_dir, \"poisoning_experiment_results.json\")\n",
    "\n",
    "    with open(results_csv_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=[\n",
    "            \"poisoning_rate\", \"accuracy_before\", \"precision_before\", \"recall_before\", \"f1_score_before\",\n",
    "            \"accuracy_after\", \"precision_after\", \"recall_after\", \"f1_score_after\"\n",
    "        ])\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        for poisoning_rate in poisoning_rates:\n",
    "            print(f\"\\nRunning experiment with poisoning rate: {poisoning_rate:.2f}\")\n",
    "\n",
    "            # Initialize a new model for each experiment\n",
    "            model_instance = IncrementalLearningModel(input_size=X_train.shape[1], num_classes=len(np.unique(y_train))).to(device)\n",
    "\n",
    "            # Poison data\n",
    "            poisoned_data, poisoned_labels = poison_data(X_train, y_train, poisoning_rate=poisoning_rate, strategy='malicious_pattern', model=model_instance, criterion=nn.CrossEntropyLoss())\n",
    "\n",
    "            # Train model\n",
    "            model_instance.train_model(poisoned_data, poisoned_labels, X_val, y_val, num_epochs=num_epochs, lr=lr, poisoning_rate=poisoning_rate)\n",
    "\n",
    "            # Evaluate model before replay mechanism\n",
    "            print(\"\\nEvaluating model before replay...\")\n",
    "            accuracy_before, precision_before, recall_before, f1_before = model_instance.evaluate(X_test, y_test, poisoning_rate)\n",
    "\n",
    "            # Apply replay mechanism\n",
    "            print(\"\\nApplying replay mechanism...\")\n",
    "            replay_mechanism(model_instance, replay_data, poisoned_data[:50], replay_labels, poisoned_labels[:50], num_epochs=5, lr=lr)\n",
    "\n",
    "            # Evaluate model after replay mechanism\n",
    "            print(\"\\nEvaluating model after replay...\")\n",
    "            accuracy_after, precision_after, recall_after, f1_after = model_instance.evaluate(X_test, y_test, poisoning_rate)\n",
    "\n",
    "            # Store results\n",
    "            result = {\n",
    "                \"poisoning_rate\": poisoning_rate,\n",
    "                \"accuracy_before\": accuracy_before,\n",
    "                \"precision_before\": precision_before,\n",
    "                \"recall_before\": recall_before,\n",
    "                \"f1_score_before\": f1_before,\n",
    "                \"accuracy_after\": accuracy_after,\n",
    "                \"precision_after\": precision_after,\n",
    "                \"recall_after\": recall_after,\n",
    "                \"f1_score_after\": f1_after\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "            # Write results to CSV\n",
    "            csv_writer.writerow(result)\n",
    "\n",
    "    # Save results as JSON\n",
    "    with open(results_json_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_replay_impact(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86524721-ec24-4f2f-b19d-584446b58244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract replay data from training data\n",
    "replay_data, _, replay_labels, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
    "\n",
    "# Define different levels of poisoning rates to evaluate\n",
    "poisoning_rates = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]  # Poisoning rates\n",
    "\n",
    "# Initialize the model\n",
    "model = IncrementalLearningModel(input_size=X_train.shape[1], num_classes=len(np.unique(y_train))).to(device)\n",
    "\n",
    "# Run the poisoning experiments\n",
    "run_poisoning_experiment_with_replay(\n",
    "    model, X_train, y_train, X_val, y_val, X_test, y_test, poisoning_rates, replay_data, replay_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cacc7-948d-43d9-9d6f-359c15aba21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pytorch_gpu",
   "language": "python",
   "name": "tf_pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
